{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train-mask-rcnn-network.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Burx_xjTKPEr",
        "-kkbYcZvI2bD"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AbZb5TV0HUc"
      },
      "source": [
        "# Train a Mask-RCNN\n",
        "\n",
        "Uses `detectron2` to train as Mask-RCNN to segment synthetic yeast cells. A default data set is downloaded, but one can also inject the `create-synthetic-dataset-for-training` notebook. In `labels.json` / `labels.umsgpack`.\n",
        "\n",
        "Be very carefull running the code, creating a model needs almost all of Colab's 12 GB RAM, rerunning things several times may cause out memory crashes. Training takes about 8 hours for 20.000 iterations. However, performance should have converged around 4.000 iterations.\n",
        "\n",
        "This notebook was tested on Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qymwIaHdI-Lw"
      },
      "source": [
        "## Install and import\n",
        "\n",
        "Installs the appropriate libraries, mainly `detectron2`.\n",
        "\n",
        "<font color='black' size='6'>Ensure to </font><font color='red' size='6'>**restart the runtime**</font><font color='black' size='6'> on Colab after everything is installed successfully, to ensure everything was imported correctly.</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SLDJY7cpGBs3",
        "outputId": "18d4e082-1b28-436e-9d12-fe1f6fdc6440"
      },
      "source": [
        "!pip3 install -U Pillow\n",
        "\n",
        "%load_ext tensorboard\n",
        "import os\n",
        "import numpy\n",
        "\n",
        "# Install detectron2 based on the installed version of torch,\n",
        "# we assume torchvision is already installed as is the case on Google Colab.\n",
        "try:\n",
        "  import detectron2\n",
        "except ImportError:\n",
        "  import torch\n",
        "  torch_version, cuda_version = torch.__version__.split('+cu')\n",
        "  torch_version = '.'.join(torch_version.split('.')[:2])\n",
        "  if (torch_version, cuda_version) not in {('1.8', '101')}:\n",
        "    warnings.warn(\n",
        "        f'Untested version combination: cuda ({cuda_version}), torch ({torch_version})\\n'\n",
        "        'Check https://github.com/facebookresearch/detectron2/blob/master/INSTALL.md\\n'\n",
        "        'and https://pytorch.org/\\n'\n",
        "        'on how to install detectron2 with adequate torch and torchvision '\n",
        "        'if installation fails.'\n",
        "    )\n",
        "\n",
        "  !pip3 install -U pyyaml\n",
        "  !pip3 install detectron2 -f \"https://dl.fbaipublicfiles.com/detectron2/wheels/cu{cuda_version}/torch{torch_version}/index.html\"\n",
        "  import detectron2\n",
        "\n",
        "try:\n",
        "  import umsgpack\n",
        "  from download import download\n",
        "except ImportError:\n",
        "  !pip3 install umsgpack download\n",
        "  import umsgpack\n",
        "  from download import download\n",
        "\n",
        "# Install the yeastcells-detection-maskrcnn from github if unavailable.\n",
        "try:\n",
        "  # raise ImportError()\n",
        "  from yeastcells.train import create_model, train\n",
        "except ImportError:\n",
        "  !test -e yeastcells-detection-maskrcnn || git clone https://github.com/ymzayek/yeastcells-detection-maskrcnn.git\n",
        "  !cd yeastcells-detection-maskrcnn; git pull origin main\n",
        "  !pip3 install ./yeastcells-detection-maskrcnn\n",
        "  from yeastcells.train import create_model, train\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: Pillow in /usr/local/lib/python3.7/dist-packages (8.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Burx_xjTKPEr"
      },
      "source": [
        "## Load data\n",
        "\n",
        "A default data set is downloaded, but you could use one created with the `create-synthetic-dataset-for-training` notebook. For example by mounting your Google Drive to both notebooks. This file is reasonably large, and the download might time out. Please be patient and try again. If the download abort midway, try again as it will continue where it left off."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC2Tn9IldNcz"
      },
      "source": [
        "data_path = f'/content/synthetic-yeast-cells-data'\n",
        "\n",
        "download(\n",
        "    'https://datascience.web.rug.nl/synthetic-yeast-cells-data-v10.zip',\n",
        "    'synthetic-yeast-cells-data-v10.zip')\n",
        "\n",
        "# Unzip again if there aren't 1000 files in the data path (heuritic)\n",
        "# Patient users may unzip always\n",
        "# If the download is clipped, just restart the cell and it will continue.\n",
        "file_count_estimate = !ls '{data_path}/'* | cat\n",
        "if len(file_count_estimate) < 1000:\n",
        " os.makedirs(data_path, exist_ok=True)\n",
        " !cd '{data_path}' && unzip '/content/synthetic-yeast-cells-data-v10.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kkbYcZvI2bD"
      },
      "source": [
        "## Tensorboard\n",
        "\n",
        "Monitor learning curves at the time series tab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE3TCMd4hGhx",
        "outputId": "d4326812-6a7b-4087-96e0-335dc6692957"
      },
      "source": [
        "%tensorboard --logdir /content/tensorboard/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFIClUIPM7HM"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ6AKz8dXVDg"
      },
      "source": [
        "#set path to model_final.pth\n",
        "version = 'v1'\n",
        "run = 1\n",
        "model_path = f'/content/model-{version}'\n",
        "\n",
        "#load model\n",
        "config = create_model(\n",
        "    model_path,\n",
        "    device='cuda:0',\n",
        "    data_workers=2,\n",
        "    batch_size=2,\n",
        "    learning_rate=0.00025,\n",
        "    max_iter=20000,\n",
        "    # max_iter=2000,\n",
        "    pretrained=\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\",\n",
        "    tensorboard=f'/content/tensorboard/yeast-cells-mask-rcnn-run-{run}'\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MV-hF3GNYDL6",
        "outputId": "1869c90e-9dbb-42d1-ffb2-8f4b98e77e02"
      },
      "source": [
        "trainer = train(\n",
        "    config,\n",
        "    data_path\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/18 14:55:31 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  ... removed model details manually ...\n",
            ")\n",
            "\u001b[32m[03/18 14:55:31 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 20000 images left.\n",
            "\u001b[32m[03/18 14:55:33 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
            "\u001b[36m|  category  | #instances   |\n",
            "|:----------:|:-------------|\n",
            "| yeast_cell | 1977043      |\n",
            "|            |              |\u001b[0m\n",
            "\u001b[32m[03/18 14:55:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[03/18 14:55:33 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[03/18 14:55:33 d2.data.common]: \u001b[0mSerializing 20000 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[03/18 14:55:40 d2.data.common]: \u001b[0mSerialized dataset takes 1055.97 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/18 14:55:40 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "model_final_f10217.pkl: 178MB [00:17, 10.4MB/s]                           \n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[03/18 14:56:00 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[03/18 14:56:27 d2.utils.events]: \u001b[0m eta: 7:31:05  iter: 19  total_loss: 9.604  loss_cls: 0.6163  loss_box_reg: 0.4482  loss_mask: 0.6877  loss_rpn_cls: 6.81  loss_rpn_loc: 0.9876  time: 1.3529  data_time: 0.0360  lr: 4.9953e-06  max_mem: 2563M\n",
            "\u001b[32m[03/18 14:56:55 d2.utils.events]: \u001b[0m eta: 7:28:17  iter: 39  total_loss: 4.303  loss_cls: 0.6114  loss_box_reg: 0.5155  loss_mask: 0.68  loss_rpn_cls: 1.654  loss_rpn_loc: 0.8095  time: 1.3548  data_time: 0.0089  lr: 9.9902e-06  max_mem: 2563M\n",
            "\u001b[32m[03/18 14:57:20 d2.utils.events]: \u001b[0m eta: 7:22:46  iter: 59  total_loss: 2.838  loss_cls: 0.6135  loss_box_reg: 0.5202  loss_mask: 0.6668  loss_rpn_cls: 0.3622  loss_rpn_loc: 0.7236  time: 1.3223  data_time: 0.0085  lr: 1.4985e-05  max_mem: 2563M\n",
            "... Removed many steps manually ...\n",
            "\u001b[32m[03/18 19:12:37 d2.utils.events]: \u001b[0m eta: 3:11:50  iter: 11519  total_loss: 0.9401  loss_cls: 0.09366  loss_box_reg: 0.2324  loss_mask: 0.252  loss_rpn_cls: 0.07964  loss_rpn_loc: 0.2787  time: 1.3352  data_time: 0.0112  lr: 0.00025  max_mem: 2563M\n",
            "\u001b[32m[03/18 19:13:04 d2.utils.events]: \u001b[0m eta: 3:11:26  iter: 11539  total_loss: 0.9302  loss_cls: 0.09498  loss_box_reg: 0.2189  loss_mask: 0.2583  loss_rpn_cls: 0.09404  loss_rpn_loc: 0.2724  time: 1.3353  data_time: 0.0117  lr: 0.00025  max_mem: 2563M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXUrFbWouWzH"
      },
      "source": [
        "##Download\n",
        "\n",
        "Download the resulting `final_model.pth`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwIGzUAHuXGN"
      },
      "source": [
        "files.download(f'/content/tensorboard/yeast-cells-mask-rcnn-run-{run}/final_model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
